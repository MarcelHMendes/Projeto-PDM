{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1143992b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/17 04:11:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"2g\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af7a5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\").csv(\"data/final_dataset.csv\")\n",
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a7f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, explode, col, desc\n",
    "from pyspark.ml import Pipeline \n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "from pyspark.ml.feature import StringIndexer \n",
    "from pyspark.ml.classification import NaiveBayes \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "indexers = [\n",
    "StringIndexer(inputCol=\"Flow ID\", outputCol = \"flowid_index\"),  \n",
    "StringIndexer(inputCol=\"Dst IP\", outputCol = \"dstip_index\"),\n",
    "StringIndexer(inputCol=\"FIN Flag Cnt\", outputCol = \"fin_index\"),\n",
    "StringIndexer(inputCol=\"SYN Flag Cnt\", outputCol = \"syn_index\"),\n",
    "StringIndexer(inputCol=\"URG Flag Cnt\", outputCol = \"urg_index\"),\n",
    "StringIndexer(inputCol=\"PSH Flag Cnt\", outputCol = \"cwe_index\"),\n",
    "StringIndexer(inputCol=\"ECE Flag Cnt\", outputCol = \"ece_index\"),\n",
    "StringIndexer(inputCol=\"Label\", outputCol = \"label\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f0fcf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m df1 \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtoPandas()\n\u001b[1;32m     13\u001b[0m df\u001b[38;5;241m.\u001b[39munpersist()\n\u001b[0;32m---> 14\u001b[0m indexed_rows_df \u001b[38;5;241m=\u001b[39m \u001b[43mPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(df1)\n\u001b[1;32m     15\u001b[0m indexed_rows_df\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'dataset'"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=indexers)\n",
    "df = df.select(\"Flow ID\",   \n",
    "               \"Dst IP\", \n",
    "               \"FIN Flag Cnt\", \n",
    "               \"SYN Flag Cnt\", \n",
    "               \"URG Flag Cnt\",\n",
    "               \"PSH Flag Cnt\",\n",
    "               \"ECE Flag Cnt\",\n",
    "               \"Label\"\n",
    "              )\n",
    "df = df.sample(fraction=0.05)\n",
    "df1 = df.toPandas()\n",
    "df.unpersist()\n",
    "indexed_rows_df = Pipeline.fit(df1).transform(df1)\n",
    "indexed_rows_df.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12af918",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = [\"flowid_index\", \"dstip_index\",\"fin_index\", \"syn_index\", \"urg_index\", \"cwe_index\",\"ece_index\"],outputCol = \"features\")\n",
    "vindexed_rows_df = VectorAssembler.transform(indexed_rows_df)\n",
    "vindexed_rows_df.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d58b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = vindexed_rows_df.randomSplit([0.6,0.4], 42) \n",
    "# optional value 42 is seed for sampling \n",
    "train_df = splits[0] \n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(modelType=\"multinomial\")\n",
    "nbmodel = nb.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661687d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = nbmodel.transform(test_df)\n",
    "predictions_df.show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d2606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"pr ediction\", metricName=\"accuracy\") \n",
    "nbaccuracy = evaluator.evaluate(predictions_df) \n",
    "print(\"Test accuracy = \" + str(nbaccuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
